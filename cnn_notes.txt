Originally tried feeding final FEN - causes representative problem

med_processed
Epoch 10/10
853/853 ━━━━━━━━━━━━━━━━━━━━ 3s 4ms/step - accuracy: 0.8328 - loss: 0.4420 - val_accuracy: 0.8558 - val_loss: 0.3936
Test loss: 0.8456695675849915 / Test accuracy: 0.5740466713905334


No piece tensors:
Test loss: 0.5623752474784851, Test accuracy: 0.8170650601387024
95/95 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step  
              precision    recall  f1-score   support

           0       0.84      0.80      0.82      1351
           1       0.80      0.90      0.85      1530
           2       1.00      0.01      0.02       131

    accuracy                           0.82      3012
   macro avg       0.88      0.57      0.56      3012
weighted avg       0.83      0.82      0.80      3012

Realistic test loss: 0.8945403099060059, Realistic test accuracy: 0.5804592967033386

For piece tensors
Test loss: 0.5440462827682495, Test accuracy: 0.8293492794036865
95/95 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step 
              precision    recall  f1-score   support

           0       0.83      0.86      0.84      1351
           1       0.83      0.88      0.85      1530
           2       1.00      0.01      0.02       131

    accuracy                           0.83      3012
   macro avg       0.89      0.58      0.57      3012
weighted avg       0.84      0.83      0.81      3012

Realistic test loss: 0.8962467312812805, Realistic test accuracy: 0.5841159820556641

Increased L2 regularization (0.01), increased patience (15):
Test loss: 0.5326062440872192, Test accuracy: 0.83432936668396
95/95 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step 
              precision    recall  f1-score   support

           0       0.83      0.86      0.84      1351
           1       0.85      0.87      0.86      1530
           2       0.54      0.21      0.30       131

    accuracy                           0.83      3012
   macro avg       0.74      0.64      0.67      3012
weighted avg       0.83      0.83      0.83      3012

Realistic test loss: 0.8932566046714783, Realistic test accuracy: 0.5898771286010742

Near final model:
              precision    recall  f1-score   support

           0       0.83      0.91      0.87     69546
           1       0.88      0.86      0.87     75458
           2       0.87      0.09      0.17      6111

    accuracy                           0.85    151115
   macro avg       0.86      0.62      0.63    151115
weighted avg       0.85      0.85      0.84    151115

Index: 0, Label: 0-1
Index: 1, Label: 1-0
Index: 2, Label: 1/2-1/2

Step evaluations
['FinalFEN', 'LastFEN1', 'LastFEN2', 'LastFEN3', 'LastFEN4', 'LastFEN5', 'LastFEN6', 'LastFEN7', 'LastFEN8', 'LastFEN9', 'LastFEN10', 'LastFEN11', 'LastFEN12', 'LastFEN13', 'LastFEN14', 'LastFEN15', 'LastFEN16', 'LastFEN17', 'LastFEN18', 'LastFEN19', 'LastFEN20']
Losses: [0.49460121989250183, 0.6558274030685425, 0.6016228199005127, 0.6960790753364563, 0.6398802399635315, 0.7267953753471375, 0.6684942841529846, 0.7498390674591064, 0.6893791556358337, 0.7703445553779602, 0.712554931640625, 0.7885956764221191, 0.7251893281936646, 0.8042467832565308, 0.7412240505218506, 0.8167039155960083, 0.7565972208976746, 0.8345667719841003, 0.7724511027336121, 0.8479306697845459, 0.7854674458503723]
Accuracies: [0.8462865948677063, 0.74530428647995, 0.7796840667724609, 0.7176611423492432, 0.7559567093849182, 0.6930046081542969, 0.7338554263114929, 0.6765447854995728, 0.71975177526474, 0.6583593487739563, 0.7025619149208069, 0.644587516784668, 0.6897855997085571, 0.6259043216705322, 0.6772416830062866, 0.6150527596473694, 0.6626070141792297, 0.5975310206413269, 0.6531161069869995, 0.5892347693443298, 0.639477014541626]
Performing realistic test
Realistic test loss: 0.8455955386161804, Realistic test accuracy: 0.5857009291648865

Expected ply of random board state: 32.35928795950104

========================================================================================================================
========================================================================================================================
========================================================================================================================

FINAL MODEL:

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                      │ (None, 18, 8, 32)           │           2,336 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 18, 8, 32)           │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 18, 8, 32)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 18, 8, 64)           │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 18, 8, 64)           │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 18, 8, 64)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 9216)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 128)                 │       1,179,776 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 128)                 │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 3)                   │             387 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 1,201,379 (4.58 MB)
 Trainable params: 1,201,187 (4.58 MB)
 Non-trainable params: 192 (768.00 B)
Epoch 1/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 191s 20ms/step - accuracy: 0.7869 - loss: 0.9041 - val_accuracy: 0.8365 - val_loss: 0.5138
Epoch 2/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 188s 20ms/step - accuracy: 0.8179 - loss: 0.5559 - val_accuracy: 0.8317 - val_loss: 0.5169
Epoch 3/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 189s 20ms/step - accuracy: 0.8191 - loss: 0.5458 - val_accuracy: 0.8403 - val_loss: 0.5013
Epoch 4/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 847s 90ms/step - accuracy: 0.8201 - loss: 0.5405 - val_accuracy: 0.8344 - val_loss: 0.5041
Epoch 5/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 192s 20ms/step - accuracy: 0.8221 - loss: 0.5354 - val_accuracy: 0.8492 - val_loss: 0.4877
Epoch 6/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 191s 20ms/step - accuracy: 0.8205 - loss: 0.5364 - val_accuracy: 0.8489 - val_loss: 0.5003
Epoch 7/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 191s 20ms/step - accuracy: 0.8198 - loss: 0.5374 - val_accuracy: 0.8372 - val_loss: 0.4950
Epoch 8/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 1084s 115ms/step - accuracy: 0.8225 - loss: 0.5318 - val_accuracy: 0.8245 - val_loss: 0.5229
Epoch 9/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 187s 20ms/step - accuracy: 0.8226 - loss: 0.5320 - val_accuracy: 0.8470 - val_loss: 0.4835
Epoch 10/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 194s 21ms/step - accuracy: 0.8230 - loss: 0.5301 - val_accuracy: 0.8538 - val_loss: 0.4744
Epoch 11/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 190s 20ms/step - accuracy: 0.8220 - loss: 0.5327 - val_accuracy: 0.8521 - val_loss: 0.4726
Epoch 12/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 189s 20ms/step - accuracy: 0.8224 - loss: 0.5295 - val_accuracy: 0.8575 - val_loss: 0.4847
Epoch 13/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 188s 20ms/step - accuracy: 0.8223 - loss: 0.5301 - val_accuracy: 0.8546 - val_loss: 0.4876
Epoch 14/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 970s 103ms/step - accuracy: 0.8213 - loss: 0.5305 - val_accuracy: 0.8566 - val_loss: 0.4701
Epoch 15/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 187s 20ms/step - accuracy: 0.8217 - loss: 0.5308 - val_accuracy: 0.8559 - val_loss: 0.4679
Epoch 16/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 188s 20ms/step - accuracy: 0.8231 - loss: 0.5300 - val_accuracy: 0.8309 - val_loss: 0.5007
Epoch 17/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 287s 30ms/step - accuracy: 0.8220 - loss: 0.5302 - val_accuracy: 0.8400 - val_loss: 0.4955
Epoch 18/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 190s 20ms/step - accuracy: 0.8217 - loss: 0.5302 - val_accuracy: 0.8417 - val_loss: 0.4880
Epoch 19/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 190s 20ms/step - accuracy: 0.8223 - loss: 0.5280 - val_accuracy: 0.8428 - val_loss: 0.4799
Epoch 20/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 191s 20ms/step - accuracy: 0.8225 - loss: 0.5274 - val_accuracy: 0.8499 - val_loss: 0.4696
Epoch 21/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 272s 29ms/step - accuracy: 0.8213 - loss: 0.5311 - val_accuracy: 0.8329 - val_loss: 0.4972
Epoch 22/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 200s 21ms/step - accuracy: 0.8211 - loss: 0.5295 - val_accuracy: 0.8501 - val_loss: 0.4783
Epoch 23/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 203s 22ms/step - accuracy: 0.8232 - loss: 0.5265 - val_accuracy: 0.8527 - val_loss: 0.4701
Epoch 24/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 195s 21ms/step - accuracy: 0.8219 - loss: 0.5291 - val_accuracy: 0.8287 - val_loss: 0.5040
Epoch 25/30
9445/9445 ━━━━━━━━━━━━━━━━━━━━ 203s 21ms/step - accuracy: 0.8232 - loss: 0.5275 - val_accuracy: 0.8485 - val_loss: 0.4699
Test loss: 0.467939168214798, Test accuracy: 0.8559176921844482
4723/4723 ━━━━━━━━━━━━━━━━━━━━ 11s 2ms/step    
              precision    recall  f1-score   support

           0       0.88      0.85      0.86     69546
           1       0.84      0.92      0.88     75458
           2       0.78      0.12      0.21      6111

    accuracy                           0.86    151115
   macro avg       0.83      0.63      0.65    151115
weighted avg       0.85      0.86      0.84    151115

Index: 0, Label: 0-1
Index: 1, Label: 1-0
Index: 2, Label: 1/2-1/2

Expected ply of random board state: 32.35928795950104

Step evaluations
['FinalFEN', 'LastFEN1', 'LastFEN2', 'LastFEN3', 'LastFEN4', 'LastFEN5', 'LastFEN6', 'LastFEN7', 'LastFEN8', 'LastFEN9', 'LastFEN10', 'LastFEN11', 'LastFEN12', 'LastFEN13', 'LastFEN14', 'LastFEN15', 'LastFEN16', 'LastFEN17', 'LastFEN18', 'LastFEN19', 'LastFEN20']
Losses: [0.47064846754074097, 0.6733251214027405, 0.5794519186019897, 0.7181800007820129, 0.6180264949798584, 0.751069188117981, 0.6437886357307434, 0.7772663831710815, 0.6623750925064087, 0.8002511858940125, 0.6852045655250549, 0.822898268699646, 0.6970639228820801, 0.8393971920013428, 0.7104772329330444, 0.8514080047607422, 0.7246571779251099, 0.8695474863052368, 0.7378684878349304, 0.8838514685630798, 0.7493375539779663]
Accuracies: [0.8607221245765686, 0.7312338352203369, 0.8040419220924377, 0.7022632360458374, 0.7808787226676941, 0.6736576557159424, 0.7653481364250183, 0.6542443633079529, 0.7554589509963989, 0.6329395174980164, 0.7384681701660156, 0.6164796948432922, 0.7299395799636841, 0.5966682434082031, 0.7226720452308655, 0.5829295516014099, 0.709597110748291, 0.5661379098892212, 0.7011681199073792, 0.5499435663223267, 0.6899183392524719]
Performing realistic test
Realistic test loss: 0.8484961986541748, Realistic test accuracy: 0.5933298468589783

Dummy evaluations
Naive test loss: 0.9109998941421509, Naive test accuracy: 0.4528956413269043